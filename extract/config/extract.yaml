e1:
  db_info:
    base_url: "etvonboardingapi-dev.abc.com/dbinfo"

  metadata_info:
    base_url: "etvonboardingapi-dev.abc.com/"
    endpoint: "service-request/table?table_extract_request_id={}"

  status:
    base_url: etvonboardingapi-dev.abc.com/service-request/update-status

  scrub_url:
    url: "ntd01.az.abc.com:6066/v1/submissions/create"
    spark_master: spark://ntd01.az.abc.com:6066

  primary_key:
    base_url: "etvonboardingapi-dev.abc.com/"
    endpoint: "tablemetadata/get-primary-key-columns"

e2:
  db_info:
    base_url: "etvonboardingapi-qa.abc.com/dbinfo"

  metadata_info:
    base_url: "etvonboardingapi-qa.abc.com/"
    endpoint: "service-request/table?table_extract_request_id={}"

  status:
    base_url: etvonboardingapi-qa.abc.com/service-request/update-status

  scrub_url:
    url: "ntq01.az.abc.com:6066/v1/submissions/create"
    spark_master: spark://ntq01.az.abc.com:6066

  primary_key:
    base_url: "etvonboardingapi-qa.abc.com/"
    endpoint: "tablemetadata/get-primary-key-columns"

e3:
  db_info:
    base_url: "etvonboardingapi.abc.com/dbinfo"

  metadata_info:
    base_url: "etvonboardingapi.abc.com/"
    endpoint: "service-request/table?table_extract_request_id={}"

  status:
    base_url: etvonboardingapi.abc.com/service-request/update-status

  scrub_url:
    url: "nt01.az.abc.com:6066/v1/submissions/create"
    spark_master: spark://nt01.az.abc.com:6066

  primary_key:
    base_url: "etvonboardingapi.abc.com/"
    endpoint: "tablemetadata/get-primary-key-columns"

keys_path: "/abc/tt/data_masking/scrubbing"
scrub_keys_path: "file:///abc/data/scrub_keys/"
vault_path: "/opt/hvault/secrets/secrets"

scrub:
  base_path: "/abc/tt/data_masking/scrubbing/"
  main_file: "python/query_gen_main.py"

drivers:
  oracle: "oracle.jdbc.driver.OracleDriver"
  SQLServer: "com.microsoft.sqlserver.jdbc.SQLServerDriver"
  postgress: "org.postgresql.Driver"

transform_data_params:
  default_value: 'NA'

extract_data_params:
  interval: '30'
  start_date_values: '10'
  table_size_gb: 5

output_path:
  output_format: "org.apache.spark.sql.execution.datasource.csv.CSVFileFoemat"
  output_path_to_NAS: "file://abc/data/"

hiped_jar: '/abc/tt/data_masking/hiped_udf/libs/bulk-crypto-lt-1.1-SNAPSHOT-jar-with-dependencies.jar'

